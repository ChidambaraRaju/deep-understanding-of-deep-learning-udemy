# A Deep Understanding of Deep Learning ‚Äî Notes & Code (Udemy Course)

This repository contains my personal notes, code implementations, code-challenges, and mini-projects from the Udemy course **‚ÄúA Deep Understanding of Deep Learning (with Python Intro)‚Äù** by **Mike X Cohen**.

My goal is to build a strong, intuitive understanding of deep learning ‚Äî not just how to use the APIs, but *why* things work the way they do, the math behind the models, and how to reason about architectures, optimization, and training dynamics.

---

## üéØ Course Focus

This course is designed to teach deep learning from first principles using a **scientific, experimental approach**. It emphasizes:

- The theory and math behind deep learning  
- Intuition through visualizations  
- Understanding neural network mechanisms  
- PyTorch-based implementations  
- Lots of coding exercises & code-challenges  
- Real experiments to study model behavior  
- Learning best practices like regularization, metaparameters, normalization, and weight initialization  
- CNNs, Autoencoders, RNNs, GANs, Transfer Learning, Style Transfer  
- Hands-on milestone projects  


This structure will grow as I progress through the course.

---

## üß† Topics Covered in this course

### **1Ô∏è‚É£ Deep Learning Foundations**
- How neural networks learn  
- Gradient descent (1D, 2D, parametric experiments)  
- Loss functions, cross-entropy, softmax  
- Vanishing/exploding gradients  
- Backpropagation math  
- Understanding ANN architecture  

### **2Ô∏è‚É£ Artificial Neural Networks (ANNs)**
- Forward & backward propagation  
- Regression & classification networks  
- Hidden units, depth vs breadth  
- Manual & automatic dataset handling  
- Overfitting, cross-validation  

### **3Ô∏è‚É£ Regularization & Metaparameters**
- Dropout, L1/L2 regularization  
- Batch normalization  
- Activation functions (ReLU, variants, comparisons)  
- Optimizers: SGD, Momentum, RMSProp, Adam  
- Learning rate decay & selection  

### **4Ô∏è‚É£ Feedforward Networks & Data Handling**
- FFN architecture  
- MNIST experiments  
- Balanced/unbalanced data  
- Data augmentation  
- Saving/loading models  

### **5Ô∏è‚É£ Weight Initialization & Autoencoders**
- Xavier, Kaiming initialization  
- Weight variance experiments  
- Denoising autoencoders  
- Latent code analysis  
- Tied weights  

### **6Ô∏è‚É£ Convolutional Neural Networks (CNNs)**
- Convolution math, kernels, feature maps  
- Stride, padding, transpose conv  
- Pooling (max/mean)  
- CNN architecture  
- EMNIST, CIFAR-10 projects  

### **7Ô∏è‚É£ Transfer Learning**
- When & why transfer learning works  
- Feature reuse  
- ResNet-18, VGG-16  
- Pretraining with autoencoders  

### **8Ô∏è‚É£ Style Transfer**
- Gram matrix  
- Style/content loss  
- PyTorch based style transfer projects  

### **9Ô∏è‚É£ Generative Models (GANs)**
- Linear GAN  
- CNN-based GANs  
- MNIST, FMNIST, CIFAR GANs  

### **üîü Recurrent Neural Networks**
- RNNs, GRUs, LSTMs  
- Sequence prediction  
- Embeddings  
- Text generation  

### **1Ô∏è‚É£1Ô∏è‚É£ Ethics of Deep Learning**
- Bias, accountability, job impact  
- Real-world case studies  

### **1Ô∏è‚É£2Ô∏è‚É£ Python Foundations (Optional Section)**
- Python basics, NumPy, Pandas  
- Functions, OOP, flow control  
- Plotting and visualization  

---

## üöÄ My Learning Goals

- Build **deep intuition** of how neural networks behave  
- Strengthen **PyTorch skills** through structured coding challenges  
- Document everything with simple explanations 
- Maintain a high-quality GitHub reference for future projects  
- Practice real deep learning experiments like a researcher  

---

## üìå Progress Status

‚úî Started the course  
üîÑ Continuous updates as I complete modules  
‚≠ê Code-Challenges and Projects will be added consistently  

---

## üìò Credits

This repository is based on the Udemy course:

**‚ÄúA Deep Understanding of Deep Learning (with Python Intro)‚Äù**  
by **Mike X Cohen**

Massive respect to the instructor for the clarity, scientific approach, and incredible depth in teaching.

---

## ‚≠ê If you find this helpful‚Ä¶

Feel free to **star** ‚≠ê the repo or follow along with the course yourself!


