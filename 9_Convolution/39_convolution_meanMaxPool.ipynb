{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning: Max and Mean Pooling\n",
    "\n",
    "## ðŸŽ¯ Objective\n",
    "Convolutional layers detect features, but **Pooling layers** summarize them. In this notebook, we explore the mechanics of **Max Pooling** and **Average Pooling**. We will see how these layers downsample feature maps to reduce computational cost and introduce translation invariance. We will also look at a unique case: using 3D pooling on 2D images to pool across channels, before building a complete mini-CNN.\n",
    "\n",
    "## ðŸ“š Key Concepts\n",
    "* **Max Pooling:** Selects the maximum value within a window. Useful for preserving dominant features (like strong edges) while discarding noise.\n",
    "* **Average Pooling:** Calculates the mean value within a window. Useful for smoothing features.\n",
    "* **Spatial vs. Volumetric:** `MaxPool2d` operates on Height/Width. `MaxPool3d` operates on Depth/Height/Width. When applied to images, \"Depth\" often corresponds to the **Channels**, allowing us to compress the number of feature maps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries\n",
    "\n",
    "We import PyTorch and its neural network module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Creating Pooling Instances\n",
    "\n",
    "We create instances of pooling layers. \n",
    "* **poolSize (3):** The window size (3x3 pixels).\n",
    "* **stride (3):** The window moves 3 pixels at a time. Because stride equals pool size, the windows do not overlap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
      "MaxPool3d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "# create a pool class instance with parameters\n",
    "\n",
    "# parameters\n",
    "poolSize = 3\n",
    "stride   = 3\n",
    "\n",
    "# create the instance\n",
    "p2 = nn.MaxPool2d(poolSize,stride=3)\n",
    "p3 = nn.MaxPool3d(poolSize,stride=3)\n",
    "\n",
    "# let's have a look at them\n",
    "print(p2)\n",
    "print(p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Applying Pooling to Data\n",
    "\n",
    "We create 2D (1 channel) and 3D (3 channel) \"images\" to see how PyTorch handles dimensions.\n",
    "\n",
    "### The \"Gotcha\" with MaxPool3d\n",
    "* **`p2(img3)`:** `MaxPool2d` applies the 3x3 reduction spatially (Height, Width) for **each channel independently**. The channel count remains 3.\n",
    "* **`p3(img3)`:** `MaxPool3d` treats the input as a volume of `(Depth, Height, Width)`. Here, the 3 color channels are treated as \"Depth\". The pool layer reduces this dimension as well (3 channels $\\to$ 1 channel), effectively mixing information from R, G, and B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D image, 2D maxpool: torch.Size([1, 1, 10, 10])\n",
      "\n",
      "3D image, 2D maxpool: torch.Size([1, 3, 10, 10])\n",
      "\n",
      "3D image, 3D maxpool: torch.Size([1, 1, 10, 10])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create image and apply maxpooling\n",
    "\n",
    "# create a 2D and a 3D image\n",
    "img2 = torch.randn(1,1,30,30)\n",
    "img3 = torch.randn(1,3,30,30)\n",
    "\n",
    "\n",
    "# all combinations of image and maxpool dimensionality\n",
    "img2Pool2 = p2(img2)\n",
    "print(f'2D image, 2D maxpool: {img2Pool2.shape}\\n' )\n",
    "\n",
    "# img2Pool3 = p3(img2)\n",
    "# print(f'2D image, 3D maxpool: {img2Pool3.shape}\\n' )\n",
    "\n",
    "img3Pool2 = p2(img3)\n",
    "print(f'3D image, 2D maxpool: {img3Pool2.shape}\\n' )\n",
    "\n",
    "img3Pool3 = p3(img3)\n",
    "print(f'3D image, 3D maxpool: {img3Pool3.shape}\\n' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Simple CNN\n",
    "\n",
    "Now we combine convolution, activation, and pooling into a small network `littlenet`. \n",
    "\n",
    "### Understanding the Tensor Shape Transformation\n",
    "1.  **Input:** (3, 128, 128)\n",
    "2.  **Conv2d:** 10 filters, stride 3. Output spatial dim $\\approx 128/3 = 43$. Output shape: **(10, 43, 43)**.\n",
    "3.  **AvgPool3d:** Kernel 3, Stride 3. Pools over (Depth 10, Height 43, Width 43).\n",
    "    * Depth: $10/3 \\approx 3$ channels.\n",
    "    * Spatial: $43/3 \\approx 14$ pixels.\n",
    "    * Result: **(3, 14, 14)**.\n",
    "4.  **Flatten:** $3 \\times 14 \\times 14 = 588$ units.\n",
    "5.  **Linear:** Maps 588 $\\to$ 1 output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "littlenet = nn.Sequential(\n",
    "\n",
    "    ## the conv-pool block\n",
    "    nn.Conv2d(3,10,5,3,2), # convolution layer\n",
    "    nn.ReLU(),             # activation function\n",
    "    nn.AvgPool3d(3,3),     # average-pool\n",
    "\n",
    "    ## the FFN block\n",
    "    nn.Flatten(),          # vectorize to get from image to linear\n",
    "    nn.Linear(588,1),      # FC linear layer\n",
    "    nn.Sigmoid()           # output activation\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5359]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test with a bit of data\n",
    "img = torch.rand(1,3,128,128)\n",
    "littlenet(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
